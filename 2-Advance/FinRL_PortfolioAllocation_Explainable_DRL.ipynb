{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Waterkin/trade_platform/blob/waterking/2-Advance/FinRL_PortfolioAllocation_Explainable_DRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv3IDvrobU37"
      },
      "source": [
        "# Explainable Deep Reinforcement Learning for Portfolio Managemnet: an Emprical Approach.\n",
        "\n",
        "Tutorials to use FinRL Library to perform explainable portfolio allocation in one [Jupyter Notebook](https://colab.research.google.com/drive/117v2qWo-qPC7OPd7paY1wYkOUywU_DWZ?usp=sharing)\n",
        "\n",
        "* This tutorial is based on the [portfolio allocation tutorial](https://github.com/AI4Finance-Foundation/FinRL/blob/master/FinRL_portfolio_allocation_NeurIPS_2020.ipynb) in FinRL Library.\n",
        "* This blog is based on our paper: Explainable Deep Reinforcement Learning for Portfolio Managemnet: an Emprical Approach\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kHCfEiTA80V"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUmLTmoQA7_w"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12v1i0jVkg48"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L63HKnWvkirx"
      },
      "source": [
        "This problem is to empirically explain the trading performance of DRL agents for the portfolio management task.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed portfolio weights that the agent interacts with the\n",
        "environment. Each element in the portfolio weights is between [0, 1].\n",
        "\n",
        "* Reward function: r(s, a, s‚Ä≤) is the incentive mechanism for an agent to learn a better action. The logorithmic rate of portfolio return when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s‚Ä≤) = ln(v'/v), where v‚Ä≤ and v represent the portfolio\n",
        "values at state s‚Ä≤ and s, respectively\n",
        "\n",
        "* State: The state space describes  an agent‚Äôs perception of a market.  Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "We use Yahoo Finance API as the data source.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_emqQCCklVt"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVCcCalAknGn"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pT8a0fvhA_TW",
        "outputId": "bcafd8ec-f344-4570-bc13-489506628d12",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting plotly==4.4.1\n",
            "  Downloading plotly-4.4.1-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting retrying>=1.3.3 (from plotly==4.4.1)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from plotly==4.4.1) (1.17.0)\n",
            "Downloading plotly-4.4.1-py2.py3-none-any.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: retrying, plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "Successfully installed plotly-4.4.1 retrying-1.3.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_plotly_utils",
                  "plotly"
                ]
              },
              "id": "0fb916c988014b65b0b1752e2fe78769"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-22 15:32:08--  https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/99037241/9dc3a580-286a-11e9-8a21-4312b7c8a512?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250222%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250222T153209Z&X-Amz-Expires=300&X-Amz-Signature=13d0a37de0ad93e7a392fed0eb956b90097a5494c2f0fcab4a715c96e6f8e301&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dorca-1.2.1-x86_64.AppImage&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-02-22 15:32:09--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/99037241/9dc3a580-286a-11e9-8a21-4312b7c8a512?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250222%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250222T153209Z&X-Amz-Expires=300&X-Amz-Signature=13d0a37de0ad93e7a392fed0eb956b90097a5494c2f0fcab4a715c96e6f8e301&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dorca-1.2.1-x86_64.AppImage&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51607939 (49M) [application/octet-stream]\n",
            "Saving to: ‚Äò/usr/local/bin/orca‚Äô\n",
            "\n",
            "/usr/local/bin/orca 100%[===================>]  49.22M  36.1MB/s    in 1.4s    \n",
            "\n",
            "2025-02-22 15:32:12 (36.1 MB/s) - ‚Äò/usr/local/bin/orca‚Äô saved [51607939/51607939]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2 libfontenc1 libgail-common\n",
            "  libgail18 libgtk2.0-bin libgtk2.0-common librsvg2-common libxfont2 libxkbfile1 x11-xkb-utils\n",
            "  xfonts-base xfonts-encodings xfonts-utils xserver-common\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2 libfontenc1 libgail-common\n",
            "  libgail18 libgconf-2-4 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common librsvg2-common libxfont2\n",
            "  libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 20 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 11.1 MB of archives.\n",
            "After this operation, 27.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdbus-glib-1-2 amd64 0.112-2build1 [65.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gconf2-common all 3.2.6-7ubuntu2 [698 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgconf-2-4 amd64 3.2.6-7ubuntu2 [86.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gconf-service-backend amd64 3.2.6-7ubuntu2 [59.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gconf-service amd64 3.2.6-7ubuntu2 [17.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 11.1 MB in 3s (4,011 kB/s)\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libdbus-glib-1-2_0.112-2build1_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.112-2build1) ...\n",
            "Selecting previously unselected package gconf2-common.\n",
            "Preparing to unpack .../01-gconf2-common_3.2.6-7ubuntu2_all.deb ...\n",
            "Unpacking gconf2-common (3.2.6-7ubuntu2) ...\n",
            "Selecting previously unselected package libgconf-2-4:amd64.\n",
            "Preparing to unpack .../02-libgconf-2-4_3.2.6-7ubuntu2_amd64.deb ...\n",
            "Unpacking libgconf-2-4:amd64 (3.2.6-7ubuntu2) ...\n",
            "Selecting previously unselected package gconf-service-backend.\n",
            "Preparing to unpack .../03-gconf-service-backend_3.2.6-7ubuntu2_amd64.deb ...\n",
            "Unpacking gconf-service-backend (3.2.6-7ubuntu2) ...\n",
            "Selecting previously unselected package gconf-service.\n",
            "Preparing to unpack .../04-gconf-service_3.2.6-7ubuntu2_amd64.deb ...\n",
            "Unpacking gconf-service (3.2.6-7ubuntu2) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../05-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../06-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../07-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../08-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../09-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../10-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../11-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../12-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../13-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../14-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../15-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../16-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../17-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../18-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../19-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up gconf2-common (3.2.6-7ubuntu2) ...\n",
            "\n",
            "Creating config file /etc/gconf/2/path with new version\n",
            "Setting up libdbus-glib-1-2:amd64 (0.112-2build1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up libgconf-2-4:amd64 (3.2.6-7ubuntu2) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up gconf-service (3.2.6-7ubuntu2) ...\n",
            "Setting up gconf-service-backend (3.2.6-7ubuntu2) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting wrds\n",
            "  Downloading wrds-3.3.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<=24.2 in /usr/local/lib/python3.11/dist-packages (from wrds) (24.2)\n",
            "Requirement already satisfied: pandas<2.3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from wrds) (2.2.2)\n",
            "Collecting psycopg2-binary<2.10,>=2.9 (from wrds)\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.11/dist-packages (from wrds) (2.0.38)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3,>=2.2->wrds) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3,>=2.2->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3,>=2.2->wrds) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3,>=2.2->wrds) (2025.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.1,>=2->wrds) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.1,>=2->wrds) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.17.0)\n",
            "Downloading wrds-3.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary, wrds\n",
            "Successfully installed psycopg2-binary-2.9.10 wrds-3.3.0\n",
            "Collecting swig\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.3.0\n",
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:10\n",
            "üîÅ Restarting kernel...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 125728 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-8qajqrwy\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-8qajqrwy\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 8cf3cacc6f570d26b430e403ea522c8fe9e6876a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git (from finrl==0.3.6)\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5xixnq0n/elegantrl_d5b414b4fe734dbb99213331e4156239\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5xixnq0n/elegantrl_d5b414b4fe734dbb99213331e4156239\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit 62bf617fa87cf82b9fbf88307715d93b8ab8ee80\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting alpaca-py<0.38,>=0.37 (from finrl==0.3.6)\n",
            "  Downloading alpaca_py-0.37.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting alpaca-trade-api<4,>=3 (from finrl==0.3.6)\n",
            "  Downloading alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting ccxt<4,>=3 (from finrl==0.3.6)\n",
            "  Downloading ccxt-3.1.60-py2.py3-none-any.whl.metadata (108 kB)\n",
            "Collecting exchange-calendars<5,>=4 (from finrl==0.3.6)\n",
            "  Downloading exchange_calendars-4.9-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting jqdatasdk<2,>=1 (from finrl==0.3.6)\n",
            "  Downloading jqdatasdk-1.9.7-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyfolio<0.10,>=0.9 (from finrl==0.3.6)\n",
            "  Downloading pyfolio-0.9.2.tar.gz (91 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyportfolioopt<2,>=1 (from finrl==0.3.6)\n",
            "  Downloading pyportfolioopt-1.5.6-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting ray<3,>=2 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scikit-learn<2,>=1 (from finrl==0.3.6)\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting selenium<5,>=4 (from finrl==0.3.6)\n",
            "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting stable-baselines3>=2.0.0a5 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading stable_baselines3-2.6.0a1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting stockstats<0.6,>=0.5 (from finrl==0.3.6)\n",
            "  Downloading stockstats-0.5.4-py2.py3-none-any.whl.metadata (26 kB)\n",
            "Collecting webdriver-manager<5,>=4 (from finrl==0.3.6)\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting wrds<4,>=3 (from finrl==0.3.6)\n",
            "  Using cached wrds-3.3.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting yfinance<0.3,>=0.2 (from finrl==0.3.6)\n",
            "  Downloading yfinance-0.2.54-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting msgpack<2.0.0,>=1.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting pandas>=1.5.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting pydantic<3.0.0,>=2.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/site-packages (from alpaca-py<0.38,>=0.37->finrl==0.3.6) (2.32.3)\n",
            "Collecting sseclient-py<2.0.0,>=1.7.2 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting websockets>=10.4 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading websockets-15.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting numpy>=1.11.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting urllib3<2,>1.24 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Collecting websocket-client<2,>=0.56.0 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting websockets>=10.4 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting msgpack<2.0.0,>=1.0.3 (from alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading msgpack-1.0.3.tar.gz (123 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiohttp<4,>=3.8.3 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading aiohttp-3.11.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting PyYAML==6.0.1 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting deprecation==2.1.0 (from alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from deprecation==2.1.0->alpaca-trade-api<4,>=3->finrl==0.3.6) (24.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.6) (65.6.3)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.11/site-packages (from ccxt<4,>=3->finrl==0.3.6) (2024.12.14)\n",
            "Collecting cryptography>=2.6.1 (from ccxt<4,>=3->finrl==0.3.6)\n",
            "  Downloading cryptography-44.0.1-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting aiodns>=1.1.1 (from ccxt<4,>=3->finrl==0.3.6)\n",
            "  Downloading aiodns-3.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting yarl>=1.7.2 (from ccxt<4,>=3->finrl==0.3.6)\n",
            "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "Collecting pyluach (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting toolz (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting tzdata (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting korean_lunar_calendar (from exchange-calendars<5,>=4->finrl==0.3.6)\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting six (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting SQLAlchemy>=1.2.8 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting pymysql>=0.7.6 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting thriftpy2!=0.5.1,>=0.3.9 (from jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading thriftpy2-0.5.2.tar.gz (782 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m782.3/782.3 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ipython>=3.2.3 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading ipython-8.32.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting matplotlib>=1.4.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pytz>=2014.10 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting scipy>=0.14.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting seaborn>=0.7.1 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting empyrical>=0.5.0 (from pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cvxpy>=1.1.19 (from pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading cvxpy-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Collecting ecos<3.0.0,>=2.0.14 (from pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting plotly<6.0.0,>=5.0.0 (from pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting click>=7.0 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting filelock (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting protobuf!=3.19.5,>=3.15.3 (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting aiosignal (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting frozenlist (from ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting prometheus-client>=0.7.1 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading prometheus_client-0.21.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting smart-open (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting grpcio>=1.42.0 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting pyarrow>=9.0.0 (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting fsspec (from ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn<2,>=1->finrl==0.3.6)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn<2,>=1->finrl==0.3.6)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting trio~=0.17 (from selenium<5,>=4->finrl==0.3.6)\n",
            "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium<5,>=4->finrl==0.3.6)\n",
            "  Downloading trio_websocket-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting typing_extensions~=4.9 (from selenium<5,>=4->finrl==0.3.6)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting torch<3.0,>=2.3 (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting cloudpickle (from stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting opencv-python (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pygame (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting psutil (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6) (4.67.1)\n",
            "Collecting rich (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting ale-py>=0.9.0 (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting pillow (from stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting python-dotenv (from webdriver-manager<5,>=4->finrl==0.3.6)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting psycopg2-binary<2.10,>=2.9 (from wrds<4,>=3->finrl==0.3.6)\n",
            "  Using cached psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting multitasking>=0.0.7 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/site-packages (from yfinance<0.3,>=0.2->finrl==0.3.6) (2.4.6)\n",
            "Collecting peewee>=3.16.2 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading peewee-3.17.9.tar.gz (3.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beautifulsoup4>=4.11.1 (from yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting th (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.6)\n",
            "  Downloading th-0.4.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pycares>=4.0.0 (from aiodns>=1.1.1->ccxt<4,>=3->finrl==0.3.6)\n",
            "  Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api<4,>=3->finrl==0.3.6)\n",
            "  Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance<0.3,>=0.2->finrl==0.3.6)\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/site-packages (from cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (1.17.1)\n",
            "Collecting osqp>=0.6.2 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting clarabel>=0.5.0 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting scs>=3.2.4.post1 (from cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pandas-datareader>=0.2 (from empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<1.1.0,>=0.29.1->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting decorator (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading decorator-5.2.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting matplotlib-inline (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading prompt_toolkit-3.0.50-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack_data (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.13.0 (from ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib>=1.4.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting tenacity>=6.2.0 (from plotly<6.0.0,>=5.0.0->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.0.3->alpaca-py<0.38,>=0.37->finrl==0.3.6)\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.6) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py<0.38,>=0.37->finrl==0.3.6) (3.10)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.2.8->jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Cython>=3.0.10 (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Using cached Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting ply<4.0,>=3.4 (from thriftpy2!=0.5.1,>=0.3.9->jqdatasdk<2,>=1->finrl==0.3.6)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
            "Collecting networkx (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3>=2.0.0a5->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium<5,>=4->finrl==0.3.6)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.6)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium<5,>=4->finrl==0.3.6) (1.7.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema->ray<3,>=2->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading rpds_py-0.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting wrapt (from smart-open->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting niltype<2.0,>=0.3 (from th->elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git->finrl==0.3.6)\n",
            "  Downloading niltype-1.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt<4,>=3->finrl==0.3.6) (2.22)\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting qdldl (from osqp>=0.6.2->cvxpy>=1.1.19->pyportfolioopt<2,>=1->finrl==0.3.6)\n",
            "  Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting lxml (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]>=2.0.0a5->finrl==0.3.6)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium<5,>=4->finrl==0.3.6)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting executing>=1.2.0 (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->ipython>=3.2.3->pyfolio<0.10,>=0.9->finrl==0.3.6)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<3,>=2->finrl==0.3.6)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Downloading alpaca_py-0.37.0-py3-none-any.whl (121 kB)\n",
            "Downloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ccxt-3.1.60-py2.py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exchange_calendars-4.9-py3-none-any.whl (198 kB)\n",
            "Downloading jqdatasdk-1.9.7-py3-none-any.whl (77 kB)\n",
            "Downloading pyportfolioopt-1.5.6-py3-none-any.whl (62 kB)\n",
            "Downloading ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl (67.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.6.0a1-py3-none-any.whl (184 kB)\n",
            "Downloading stockstats-0.5.4-py2.py3-none-any.whl (21 kB)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Using cached wrds-3.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading yfinance-0.2.54-py2.py3-none-any.whl (108 kB)\n",
            "Downloading aiodns-3.2.0-py3-none-any.whl (5.7 kB)\n",
            "Downloading aiohttp-3.11.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading cryptography-44.0.1-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cvxpy-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ecos-2.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
            "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
            "Downloading grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading ipython-8.32.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m825.5/825.5 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_client-0.21.1-py3-none-any.whl (54 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Using cached psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m163.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m181.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m169.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
            "Downloading trio_websocket-0.12.1-py3-none-any.whl (21 kB)\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
            "Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
            "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Downloading th-0.4.1-py3-none-any.whl (12 kB)\n",
            "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
            "Downloading clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Downloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
            "Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "Downloading niltype-1.0.2-py3-none-any.whl (5.3 kB)\n",
            "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "Downloading prompt_toolkit-3.0.50-py3-none-any.whl (387 kB)\n",
            "Downloading propcache-0.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "Downloading pycares-4.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.23.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (386 kB)\n",
            "Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading decorator-5.2.0-py3-none-any.whl (9.1 kB)\n",
            "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl (164 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "Downloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
            "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Building wheels for collected packages: finrl, msgpack, pyfolio, elegantrl, empyrical, peewee, thriftpy2\n",
            "  Building wheel for finrl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.6-py3-none-any.whl size=4695553 sha256=48f934741137e20498422d55f7386f282c69013d96378926c0da3a1259665c45\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nextfdde/wheels/22/04/d2/8ee1f0ed6a91622a6548d244772ae124a9b3795372817286a0\n",
            "  Building wheel for msgpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack: filename=msgpack-1.0.3-cp311-cp311-linux_x86_64.whl size=15688 sha256=80450543725ef7da9779a4276c177a333ab6e75ceb22ce71232def98ea8f05ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/35/da/ed9b26b510235e00e3a3c3bab7bad97b59214729662255ab3d\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88655 sha256=892d975406d47dae7d8513e4b056fd8e43878875d5e6a67d29007f1936751636\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/af/9e/7c343b822164a3147a3d395a1bcd05041c520a3bc6398fe88e\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=ElegantRL-0.3.10-py3-none-any.whl size=271972 sha256=b1c93e574fc123b20f3cc93d2fbefba3f04a1dd3ab1c1e260ae6490f84e9fc88\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nextfdde/wheels/9a/77/4d/6284111037b2dd64af9ef18d4d600d9c185cc2f6f09704e896\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39752 sha256=19ac28412fcb93faff7d536ca4ef348b816137fc53ff4d913170ba3a37b5b950\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/1d/58/a7ae5ef5c8de7c4b769f24c2584f4706564921f031b16b9cb6\n",
            "  Building wheel for peewee (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peewee: filename=peewee-3.17.9-cp311-cp311-linux_x86_64.whl size=300833 sha256=276698d5b8366114cd83b99d13461d48d1c10998b606db0389f1cd60254fe754\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/14/e4/50c88c865833085aeb91e2bd40e3a683ff434806386b8ee7bc\n",
            "  Building wheel for thriftpy2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.5.2-cp311-cp311-linux_x86_64.whl size=841170 sha256=3d811b020d0bc43600e3c1e3b0d8a6267252c1057a09d674a869c8dedfbd3c81\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/32/fa/51ae0364792430fb80858f4705c9e0cba3d6900f591f0c4495\n",
            "Successfully built finrl msgpack pyfolio elegantrl empyrical peewee thriftpy2\n",
            "Installing collected packages: wcwidth, triton, sseclient-py, sortedcontainers, pytz, py-spy, pure-eval, ptyprocess, ply, peewee, opencensus-context, nvidia-cusparselt-cu12, multitasking, msgpack, mpmath, korean_lunar_calendar, farama-notifications, distlib, colorful, wrapt, websockets, websocket-client, urllib3, tzdata, typing_extensions, traitlets, toolz, threadpoolctl, tensorboard-data-server, tenacity, sympy, soupsieve, sniffio, six, rpds-py, PyYAML, python-dotenv, pyparsing, pymysql, pyluach, pygments, pygame, pyasn1, pyarrow, psycopg2-binary, psutil, protobuf, propcache, prompt_toolkit, prometheus-client, pillow, pexpect, parso, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, niltype, networkx, multidict, mdurl, MarkupSafe, markdown, lxml, kiwisolver, joblib, h11, grpcio, greenlet, fsspec, frozenlist, fonttools, filelock, executing, deprecation, decorator, Cython, cycler, cloudpickle, click, cachetools, attrs, asttokens, annotated-types, aiohappyeyeballs, absl-py, yarl, wsproto, werkzeug, virtualenv, thriftpy2, th, tensorboardX, stack_data, SQLAlchemy, smart-open, scipy, rsa, referencing, python-dateutil, pydantic-core, pycares, pyasn1-modules, proto-plus, plotly, outcome, opencv-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib-inline, markdown-it-py, jinja2, jedi, gymnasium, googleapis-common-protos, cryptography, contourpy, beautifulsoup4, ale-py, aiosignal, webdriver-manager, trio, tensorboard, scs, scikit-learn, rich, qdldl, pydantic, pandas, nvidia-cusolver-cu12, matplotlib, jsonschema-specifications, ipython, google-auth, ecos, clarabel, aiohttp, aiodns, yfinance, wrds, trio-websocket, torch, stockstats, seaborn, pandas-datareader, osqp, jsonschema, jqdatasdk, google-api-core, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, alpaca-py, aiohttp-cors, stable-baselines3, selenium, ray, opencensus, empyrical, cvxpy, pyportfolioopt, pyfolio, finrl\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "Successfully installed Cython-3.0.12 MarkupSafe-3.0.2 PyYAML-6.0.1 SQLAlchemy-2.0.38 absl-py-2.1.0 aiodns-3.2.0 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiohttp-cors-0.7.0 aiosignal-1.3.2 ale-py-0.10.2 alpaca-py-0.37.0 alpaca-trade-api-3.2.0 annotated-types-0.7.0 asttokens-3.0.0 attrs-25.1.0 beautifulsoup4-4.13.3 cachetools-5.5.2 ccxt-3.1.60 clarabel-0.10.0 click-8.1.8 cloudpickle-3.1.1 colorful-0.5.6 contourpy-1.3.1 cryptography-44.0.1 cvxpy-1.6.1 cycler-0.12.1 decorator-5.2.0 deprecation-2.1.0 distlib-0.3.9 ecos-2.0.14 elegantrl-0.3.10 empyrical-0.5.5 exchange-calendars-4.9 executing-2.2.0 farama-notifications-0.0.4 filelock-3.17.0 finrl-0.3.6 fonttools-4.56.0 frozenlist-1.5.0 fsspec-2025.2.0 google-api-core-2.24.1 google-auth-2.38.0 googleapis-common-protos-1.68.0 greenlet-3.1.1 grpcio-1.70.0 gymnasium-1.0.0 h11-0.14.0 ipython-8.32.0 jedi-0.19.2 jinja2-3.1.5 joblib-1.4.2 jqdatasdk-1.9.7 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 kiwisolver-1.4.8 korean_lunar_calendar-0.3.1 lxml-5.3.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.0 matplotlib-inline-0.1.7 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.0.3 multidict-6.1.0 multitasking-0.0.11 networkx-3.4.2 niltype-1.0.2 numpy-2.2.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opencv-python-4.11.0.86 osqp-0.6.7.post3 outcome-1.3.0.post0 pandas-2.2.3 pandas-datareader-0.10.0 parso-0.8.4 peewee-3.17.9 pexpect-4.9.0 pillow-11.1.0 plotly-5.24.1 ply-3.11 prometheus-client-0.21.1 prompt_toolkit-3.0.50 propcache-0.3.0 proto-plus-1.26.0 protobuf-5.29.3 psutil-7.0.0 psycopg2-binary-2.9.10 ptyprocess-0.7.0 pure-eval-0.2.3 py-spy-0.4.0 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pycares-4.5.0 pydantic-2.10.6 pydantic-core-2.27.2 pyfolio-0.9.2 pygame-2.6.1 pygments-2.19.1 pyluach-2.2.0 pymysql-1.1.1 pyparsing-3.2.1 pyportfolioopt-1.5.6 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 pytz-2025.1 qdldl-0.1.7.post5 ray-2.42.1 referencing-0.36.2 rich-13.9.4 rpds-py-0.23.1 rsa-4.9 scikit-learn-1.6.1 scipy-1.15.2 scs-3.2.7.post2 seaborn-0.13.2 selenium-4.29.0 six-1.17.0 smart-open-7.1.0 sniffio-1.3.1 sortedcontainers-2.4.0 soupsieve-2.6 sseclient-py-1.8.0 stable-baselines3-2.6.0a1 stack_data-0.6.3 stockstats-0.5.4 sympy-1.13.1 tenacity-9.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 th-0.4.1 threadpoolctl-3.5.0 thriftpy2-0.5.2 toolz-1.0.0 torch-2.6.0 traitlets-5.14.3 trio-0.29.0 trio-websocket-0.12.1 triton-3.2.0 typing_extensions-4.12.2 tzdata-2025.1 urllib3-1.26.20 virtualenv-20.29.2 wcwidth-0.2.13 webdriver-manager-4.0.2 websocket-client-1.8.0 websockets-10.4 werkzeug-3.1.3 wrapt-1.17.2 wrds-3.3.0 wsproto-1.2.0 yarl-1.18.3 yfinance-0.2.54\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cycler",
                  "google",
                  "kiwisolver",
                  "matplotlib_inline",
                  "pexpect",
                  "prompt_toolkit",
                  "six",
                  "wcwidth"
                ]
              },
              "id": "1ac3546f1f704fc4a5e4ee7ebd6f64d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPortfolioOpt in /usr/local/lib/python3.11/site-packages (1.5.6)\n",
            "Requirement already satisfied: cvxpy>=1.1.19 in /usr/local/lib/python3.11/site-packages (from PyPortfolioOpt) (1.6.1)\n",
            "Requirement already satisfied: ecos<3.0.0,>=2.0.14 in /usr/local/lib/python3.11/site-packages (from PyPortfolioOpt) (2.0.14)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/site-packages (from PyPortfolioOpt) (2.2.3)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.11/site-packages (from PyPortfolioOpt) (2.2.3)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.0.0 in /usr/local/lib/python3.11/site-packages (from PyPortfolioOpt) (5.24.1)\n",
            "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.11/site-packages (from PyPortfolioOpt) (1.15.2)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/site-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (0.6.7.post3)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/site-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (0.10.0)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/site-packages (from cvxpy>=1.1.19->PyPortfolioOpt) (3.2.7.post2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas>=0.19->PyPortfolioOpt) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas>=0.19->PyPortfolioOpt) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas>=0.19->PyPortfolioOpt) (2025.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/site-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from plotly<6.0.0,>=5.0.0->PyPortfolioOpt) (24.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.11/site-packages (from osqp>=0.6.2->cvxpy>=1.1.19->PyPortfolioOpt) (0.1.7.post5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.19->PyPortfolioOpt) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "## install finrl library\n",
        "!pip install plotly==4.4.1\n",
        "!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n",
        "!chmod +x /usr/local/bin/orca\n",
        "!apt-get install xvfb libgtk2.0-0 libgconf-2-4\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
        "!pip install PyPortfolioOpt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2568cp5bU38"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them.\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNmvYN9YbU4B"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "szH0HkQdghFL"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B8bBq7nsBCfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de148180-c672-43a6-d24f-a24a1bfa6124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/pandas_datareader/compat/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  PANDAS_VERSION = LooseVersion(pd.__version__)\n",
            "/usr/local/lib/python3.11/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools\n",
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slBria_QbU4F"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEwzMkFHbU4G",
        "outputId": "2ac9f559-e550-4742-f8b9-65170668c5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (100385, 8)\n"
          ]
        }
      ],
      "source": [
        "df = YahooDownloader(start_date = '2008-01-01',\n",
        "                     end_date = '2021-09-02',\n",
        "                     ticker_list = config_tickers.DOW_30_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9UwKwzRbU4l"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007‚Äì2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5h8RbeBHMDQ",
        "outputId": "16669877-8acf-40d3-802e-4e6545006bf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    use_turbulence=False,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "df = fe.preprocess_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz9K2vul6RmK"
      },
      "source": [
        "## Add covariance matrix as states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iHVFkbWJ9_Rj"
      },
      "outputs": [],
      "source": [
        "# add covariance matrix as states\n",
        "df=df.sort_values(['date','tic'],ignore_index=True)\n",
        "df.index = df.date.factorize()[0]\n",
        "\n",
        "cov_list = []\n",
        "return_list = []\n",
        "\n",
        "# look back is one year\n",
        "lookback=252\n",
        "for i in range(lookback,len(df.index.unique())):\n",
        "  data_lookback = df.loc[i-lookback:i,:]\n",
        "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
        "  return_lookback = price_lookback.pct_change().dropna()\n",
        "  return_list.append(return_lookback)\n",
        "\n",
        "  covs = return_lookback.cov().values\n",
        "  cov_list.append(covs)\n",
        "\n",
        "\n",
        "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "df = df.merge(df_cov, on='date')\n",
        "df = df.sort_values(['date','tic']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UooHj1OgbU4v"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed portfolio weights that the agent interacts with the environment. Each element in the portfolio weights vector is non-negative and no more than 100%. Also, the sum of elements in each portfolio weight should equal to 100%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQnmN1qdk88I"
      },
      "source": [
        "## Training data split: 2009-01-01 to 2020-06-30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NrPxgv4eBQ_R"
      },
      "outputs": [],
      "source": [
        "train = data_split(df, '2009-01-01','2020-06-30')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxQTNjpblAMN"
      },
      "source": [
        "\n",
        "## Environment for Portfolio Allocation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xlfE-VERbU40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "\n",
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"A portfolio allocation environment for OpenAI gym\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            input data\n",
        "        stock_dim : int\n",
        "            number of unique stocks\n",
        "        hmax : int\n",
        "            maximum number of shares to trade\n",
        "        initial_amount : int\n",
        "            start money\n",
        "        transaction_cost_pct: float\n",
        "            transaction cost percentage per trade\n",
        "        reward_scaling: float\n",
        "            scaling factor for reward, good for training\n",
        "        state_space: int\n",
        "            the dimension of input features\n",
        "        action_space: int\n",
        "            equals stock dimension\n",
        "        tech_indicator_list: list\n",
        "            a list of technical indicator names\n",
        "        turbulence_threshold: int\n",
        "            a threshold to control risk aversion\n",
        "        day: int\n",
        "            an increment number to control date\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    _sell_stock()\n",
        "        perform sell action based on the sign of the action\n",
        "    _buy_stock()\n",
        "        perform buy action based on the sign of the action\n",
        "    step()\n",
        "        at each step the agent will return actions, then\n",
        "        we will calculate the reward, and return the next observation.\n",
        "    reset()\n",
        "        reset the environment\n",
        "    render()\n",
        "        use render to return other functions\n",
        "    save_asset_memory()\n",
        "        return account value at each time step\n",
        "    save_action_memory()\n",
        "        return actions/positions at each time step\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self,\n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day = 0):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct =transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "\n",
        "        # action_space normalization and shape is self.stock_dim\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
        "\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.terminal = False\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "        self.portfolio_value = self.initial_amount\n",
        "\n",
        "        # memorize portfolio value each step\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        # memorize portfolio return each step\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "\n",
        "        if self.terminal:\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['daily_return']\n",
        "            plt.plot(df.daily_return.cumsum(),'r')\n",
        "            plt.savefig('results/cumulative_reward.png')\n",
        "            plt.close()\n",
        "\n",
        "            plt.plot(self.portfolio_return_memory,'r')\n",
        "            plt.savefig('results/rewards.png')\n",
        "            plt.close()\n",
        "\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_daily_return.columns = ['daily_return']\n",
        "            if df_daily_return['daily_return'].std() !=0:\n",
        "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
        "                       df_daily_return['daily_return'].std()\n",
        "              print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "\n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            weights = self.softmax_normalization(actions)\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            log_portfolio_return = np.log(sum((self.data.close.values / last_day_memory.close.values)*weights))\n",
        "            # update portfolio value\n",
        "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])\n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "\n",
        "            # the reward is the new portfolio value or end portfolo value\n",
        "            self.reward = new_portfolio_value\n",
        "\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        #self.cost = 0\n",
        "        #self.trades = 0\n",
        "        self.terminal = False\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        #print(len(date_list))\n",
        "        #print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzD06X0CbU43",
        "outputId": "34c4fa14-7323-418f-d7f1-92d31e215dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 28, State Space: 28\n",
            "Feature Dimension: 4\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "tech_indicator_list = ['macd', 'rsi_30', 'cci_30', 'dx_30']\n",
        "feature_dimension = len(tech_indicator_list)\n",
        "print(f\"Feature Dimension: {feature_dimension}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jyg0_ZuVEVQ5"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"transaction_cost_pct\": 0,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": tech_indicator_list,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-1\n",
        "\n",
        "}\n",
        "\n",
        "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shimmy>=2.0"
      ],
      "metadata": {
        "id": "aLVzIbf5kQxn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTlOf8SJGdkl",
        "outputId": "f89f0911-9a9f-4dce-eaa1-78719f01a82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eKIu5UPlPnk"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* We use two DRL algorithms in FinRL library PPO andf A2C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdPe8uzflbXe"
      },
      "source": [
        "### Model 1: **A2C**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1tORf1fIcQ2",
        "outputId": "adb6cb70-2ced-4613-f3aa-f8837e6c20fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_steps': 10, 'ent_coef': 0.005, 'learning_rate': 0.0004}\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "A2C_PARAMS = {\"n_steps\": 10, \"ent_coef\": 0.005, \"learning_rate\": 0.0004}\n",
        "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DazEdrMpIdyz",
        "outputId": "08e6595b-af89-41d4-8e16-d8ce3b057ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 150       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 4.48e+08  |\n",
            "|    reward             | 2171721.0 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 1.62e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 143       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 13        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 8.13e+08  |\n",
            "|    reward             | 4131260.2 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 5.76e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6444043.31001617\n",
            "Sharpe:  0.9809682404380505\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 137       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 2.36e+08  |\n",
            "|    reward             | 1147811.8 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 4.2e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 136       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 5.37e+08  |\n",
            "|    reward             | 2674892.5 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 2.5e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 153       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 9.5e+08   |\n",
            "|    reward             | 4347629.5 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 6.93e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6147748.217141123\n",
            "Sharpe:  0.9600746171853889\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 167       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 2.74e+08  |\n",
            "|    reward             | 1322254.9 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 5.99e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 177       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.5     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 5.6e+08   |\n",
            "|    reward             | 2791287.8 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 2.62e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 188       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 9.73e+08  |\n",
            "|    reward             | 4834587.5 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 7.98e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5917601.270687833\n",
            "Sharpe:  0.939241509910906\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 197       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 3e+08     |\n",
            "|    reward             | 1471715.2 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 7.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 205       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 48        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 5.65e+08  |\n",
            "|    reward             | 2781010.8 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 2.76e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 210       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 1.1e+09   |\n",
            "|    reward             | 4953533.0 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 9.58e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6188881.498530481\n",
            "Sharpe:  0.9575723253688257\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 215       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 55        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 2.92e+08  |\n",
            "|    reward             | 1553039.8 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 7.68e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 221       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 58        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 6.68e+08  |\n",
            "|    reward             | 3185129.0 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 3.53e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 226       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 61        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 1.21e+09  |\n",
            "|    reward             | 5609484.0 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 1.07e+15  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5990047.347799568\n",
            "Sharpe:  0.9411970201308354\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 229       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 3.49e+08  |\n",
            "|    reward             | 1641903.8 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 9.85e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 233       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 68        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 6.21e+08  |\n",
            "|    reward             | 3110938.5 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 3.23e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 238       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 71        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 9.86e+08  |\n",
            "|    reward             | 5109202.5 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 8.58e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5700267.848996228\n",
            "Sharpe:  0.9268905263875257\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 239       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 3.55e+08  |\n",
            "|    reward             | 1675742.6 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 1.06e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 243       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 6.79e+08  |\n",
            "|    reward             | 3337576.8 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 3.87e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 246       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 1.27e+09  |\n",
            "|    reward             | 6044795.0 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 1.25e+15  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6009226.686554648\n",
            "Sharpe:  0.9503687463482952\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 249       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 84        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 3.46e+08  |\n",
            "|    reward             | 1644997.4 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 9.05e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 249       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 6.32e+08  |\n",
            "|    reward             | 3077844.0 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 3.4e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 252       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 1.22e+09  |\n",
            "|    reward             | 5664817.0 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 1.13e+15  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5259498.009238318\n",
            "Sharpe:  0.8838159825995427\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 254       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 94        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 4.14e+08  |\n",
            "|    reward             | 1862877.2 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 1.26e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 257       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 97        |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 7.75e+08  |\n",
            "|    reward             | 3397280.0 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 4.07e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 257       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 100       |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 1.15e+09  |\n",
            "|    reward             | 5332951.5 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 9.93e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5627739.490073801\n",
            "Sharpe:  0.9160451294192152\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 259       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | 4.56e+08  |\n",
            "|    reward             | 2013215.5 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 1.59e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 261       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 107       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 8.63e+08  |\n",
            "|    reward             | 3832566.2 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 5.4e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6472810.244558869\n",
            "Sharpe:  0.9856206616963493\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 262       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 110       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 2.04e+08  |\n",
            "|    reward             | 1062824.9 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 3.56e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 259       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 115       |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 4.89e+08  |\n",
            "|    reward             | 2452348.8 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 2.09e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 261       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 118       |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 8.73e+08  |\n",
            "|    reward             | 4362591.0 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 6.9e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6017415.349528646\n",
            "Sharpe:  0.942348109771931\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 262       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 121       |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 2.54e+08  |\n",
            "|    reward             | 1223507.6 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 5.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 262       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 125       |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 5.18e+08  |\n",
            "|    reward             | 2553471.2 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 2.15e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 264       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 128       |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 9.32e+08  |\n",
            "|    reward             | 4424912.5 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 6.75e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6007780.526736158\n",
            "Sharpe:  0.9392606192550127\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 265       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 131       |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 2.93e+08  |\n",
            "|    reward             | 1403562.2 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 6.55e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 267       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 134       |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 5.54e+08  |\n",
            "|    reward             | 2814166.5 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 2.62e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 267       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 138       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 1.13e+09  |\n",
            "|    reward             | 5055629.5 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 9.99e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5912234.5242296215\n",
            "Sharpe:  0.938531071674705\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 268       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 141       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 2.96e+08  |\n",
            "|    reward             | 1395011.4 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 6.97e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 270       |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 144       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 6.45e+08  |\n",
            "|    reward             | 2977374.0 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 3.33e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 271       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 147       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -39.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 1.14e+09  |\n",
            "|    reward             | 5489762.5 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 1.02e+15  |\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c',\n",
        "                                total_timesteps=40000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvrqTro3lhAh"
      },
      "source": [
        "### Model 2: **PPO**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXta7jVKMhV",
        "outputId": "8d4c012b-d2e0-443d-a163-ad10b13ec427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.001, 'batch_size': 128}\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "agent = DRLAgent(env = env_train)\n",
        "PPO_PARAMS = {\n",
        "    \"n_steps\": 2048,\n",
        "    \"ent_coef\": 0.005,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5XlUIszKUGx",
        "outputId": "822229c9-c3ea-4c11-b7a6-0ef880a7a7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 362       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 5         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 3891851.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5616904.457236814\n",
            "Sharpe:  0.9141203080580831\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 347          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.080395e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.94e+14     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -5.63e-06    |\n",
            "|    reward               | 2555690.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.66e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6010908.060465884\n",
            "Sharpe:  0.942045016558852\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.702045e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.41e+15     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -3.88e-06    |\n",
            "|    reward               | 1351615.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.32e+15     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 337          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.265488e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 2.52e+15     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -3.32e-06    |\n",
            "|    reward               | 5038890.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 4.69e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5629780.621935406\n",
            "Sharpe:  0.913563005397984\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.080395e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.25e+15     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -3.96e-06    |\n",
            "|    reward               | 3364405.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.56e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5760864.412382102\n",
            "Sharpe:  0.9235502790730887\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 332          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.255018e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.51e+15     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -4.6e-06     |\n",
            "|    reward               | 1590622.6    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.82e+15     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 332          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.469215e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 2.1e+15      |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -3.94e-06    |\n",
            "|    reward               | 6153413.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 4.14e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5594274.635747747\n",
            "Sharpe:  0.9089090915575048\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 333          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 49           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.090865e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.92e+15     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -3.27e-06    |\n",
            "|    reward               | 3667945.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.75e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6367020.515356146\n",
            "Sharpe:  0.9722131952564202\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 55           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.022187e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.73e+14     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -4.54e-06    |\n",
            "|    reward               | 2445915.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.93e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6097290.230434707\n",
            "Sharpe:  0.9541368726797269\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 61           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.702045e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.84e+15     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -3.75e-06    |\n",
            "|    reward               | 1350631.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.92e+15     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.080395e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 2.3e+15      |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -3.35e-06    |\n",
            "|    reward               | 5104885.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 4.75e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5943541.558357725\n",
            "Sharpe:  0.9426427965368537\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.051291e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.17e+15     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -4.14e-06    |\n",
            "|    reward               | 2958207.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.36e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5758712.686052771\n",
            "Sharpe:  0.9237598489554963\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.138603e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.57e+15     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -3.9e-06     |\n",
            "|    reward               | 1784920.1    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.24e+15     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 86           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.516953e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.93e+15     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -3.85e-06    |\n",
            "|    reward               | 6203109.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.97e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6176582.185615411\n",
            "Sharpe:  0.9619664659598285\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 93           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.469215e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.82e+15     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -3.37e-06    |\n",
            "|    reward               | 3241539.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.92e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5857684.856646689\n",
            "Sharpe:  0.933573301734587\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 328          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 99           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.858034e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.11e+15     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -4.37e-06    |\n",
            "|    reward               | 2203755.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.47e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5665285.108354744\n",
            "Sharpe:  0.922395080916228\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 328         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.96398e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -39.7       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 2.06e+15    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -3.93e-06   |\n",
            "|    reward               | 1088629.1   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 3.92e+15    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 327          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 112          |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.294592e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 2.2e+15      |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -3.2e-06     |\n",
            "|    reward               | 4491779.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 4.55e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5869673.573470362\n",
            "Sharpe:  0.9340142404717082\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 328          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.643838e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.67e+14     |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -4.69e-06    |\n",
            "|    reward               | 2800335.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.04e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6536370.9654731285\n",
            "Sharpe:  0.9864556458161059\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 326          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 125          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.265488e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -39.7        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.84e+15     |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -3.66e-06    |\n",
            "|    reward               | 1596476.9    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 3.55e+15     |\n",
            "------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "trained_ppo = agent.train_model(model=model_ppo,\n",
        "                             tb_log_name='ppo',\n",
        "                             total_timesteps=40000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Ma6YpTlnuZ"
      },
      "source": [
        "## Back-Testing\n",
        "Assume that we have $1,000,000 initial capital at 2020-01-01. We use the PPO, A2C, SVM, Linear Regression, Decision Tree, Random Foreset models to trade Dow jones 30 constituent stocks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uas8U6k455sI"
      },
      "outputs": [],
      "source": [
        "trade = data_split(df,'2020-07-01', '2021-09-02')\n",
        "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IY9FV6IZlcFf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GjE0koq1SRW5"
      },
      "outputs": [],
      "source": [
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "import pandas as pd\n",
        "from pypfopt import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "from pypfopt import objective_functions\n",
        "unique_tic = trade.tic.unique()\n",
        "unique_trade_date = trade.date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NMOUIHy3NHD",
        "outputId": "62c7c4a3-1ac2-4c51-fffe-2dd6c5432379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (295, 8)\n",
            "Annual return          0.311845\n",
            "Cumulative returns     0.374034\n",
            "Annual volatility      0.140762\n",
            "Sharpe ratio           2.006165\n",
            "Calmar ratio           3.491806\n",
            "Stability              0.950106\n",
            "Max drawdown          -0.089308\n",
            "Omega ratio            1.397014\n",
            "Sortino ratio          2.988706\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.094883\n",
            "Daily value at risk   -0.016614\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pyfolio\n",
        "%matplotlib inline\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
        "\n",
        "baseline_df = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start = '2020-07-01',\n",
        "        end =  '2021-09-01')\n",
        "\n",
        "baseline_df_stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
        "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "dji_cumpod =(baseline_returns+1).cumprod()-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUcP0AmbPaFg",
        "outputId": "3307eaef-cb8c-49e3-e604-2f10e6bb4597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1422554.1279480734\n",
            "Sharpe:  2.214066270137337\n",
            "=================================\n",
            "hit end!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:1409258.734359532\n",
            "Sharpe:  2.179591464014092\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "from pyfolio import timeseries\n",
        "\n",
        "df_daily_return_a2c, df_actions_a2c = DRLAgent.DRL_prediction(model=trained_a2c,\n",
        "                        environment = e_trade_gym)\n",
        "df_daily_return_ppo, df_actions_ppo = DRLAgent.DRL_prediction(model=trained_ppo,\n",
        "                        environment = e_trade_gym)\n",
        "time_ind = pd.Series(df_daily_return_a2c.date)\n",
        "a2c_cumpod =(df_daily_return_a2c.daily_return+1).cumprod()-1\n",
        "ppo_cumpod =(df_daily_return_ppo.daily_return+1).cumprod()-1\n",
        "DRL_strat_a2c = convert_daily_return_to_pyfolio_ts(df_daily_return_a2c)\n",
        "DRL_strat_ppo = convert_daily_return_to_pyfolio_ts(df_daily_return_ppo)\n",
        "\n",
        "perf_func = timeseries.perf_stats\n",
        "perf_stats_all_a2c = perf_func( returns=DRL_strat_a2c,\n",
        "                              factor_returns=DRL_strat_a2c,\n",
        "                                positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "perf_stats_all_ppo = perf_func( returns=DRL_strat_ppo,\n",
        "                              factor_returns=DRL_strat_ppo,\n",
        "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JF5xR6e_cZyG"
      },
      "outputs": [],
      "source": [
        "def extract_weights(drl_actions_list):\n",
        "  a2c_weight_df = {'date':[], 'weights':[]}\n",
        "  for i in range(len(drl_actions_list)):\n",
        "    date = drl_actions_list.index[i]\n",
        "    tic_list = list(drl_actions_list.columns)\n",
        "    weights_list = drl_actions_list.reset_index()[list(drl_actions_list.columns)].iloc[i].values\n",
        "    weight_dict = {'tic':[], 'weight':[]}\n",
        "    for j in range(len(tic_list)):\n",
        "      weight_dict['tic'] += [tic_list[j]]\n",
        "      weight_dict['weight'] += [weights_list[j]]\n",
        "\n",
        "    a2c_weight_df['date'] += [date]\n",
        "    a2c_weight_df['weights'] += [pd.DataFrame(weight_dict)]\n",
        "\n",
        "  a2c_weights = pd.DataFrame(a2c_weight_df)\n",
        "  return a2c_weights\n",
        "\n",
        "a2c_weights = extract_weights(df_actions_a2c)\n",
        "ppo_weights = extract_weights(df_actions_ppo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElfXZCQb1Thv"
      },
      "source": [
        "## Machine Learning Models\n",
        "\n",
        "We trained the machine learning models with technical indicators: MACD, RSI, CCI, DX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "56nqKfFAR6m_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def prepare_data(trainData):\n",
        "  train_date = sorted(set(trainData.date.values))\n",
        "  X = []\n",
        "  for i in range(0, len(train_date) - 1):\n",
        "    d = train_date[i]\n",
        "    d_next = train_date[i+1]\n",
        "    y = train.loc[train['date'] == d_next].return_list.iloc[0].loc[d_next].reset_index()\n",
        "    y.columns = ['tic', 'return']\n",
        "    x = train.loc[train['date'] == d][['tic','macd','rsi_30','cci_30','dx_30']]\n",
        "    train_piece = pd.merge(x, y, on = 'tic')\n",
        "    train_piece['date'] = [d] * len(train_piece)\n",
        "    X += [train_piece]\n",
        "  trainDataML = pd.concat(X)\n",
        "  X = trainDataML[tech_indicator_list].values\n",
        "  Y = trainDataML[['return']].values\n",
        "\n",
        "  return X, Y\n",
        "\n",
        "train_X, train_Y = prepare_data(train)\n",
        "rf_model = RandomForestRegressor(max_depth = 35,  min_samples_split = 10, random_state = 0).fit(train_X, train_Y.reshape(-1))\n",
        "dt_model = DecisionTreeRegressor(random_state = 0, max_depth=35, min_samples_split = 10 ).fit(train_X, train_Y.reshape(-1))\n",
        "svm_model =  SVR(epsilon=0.14).fit(train_X, train_Y.reshape(-1))\n",
        "lr_model = LinearRegression().fit(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIu0h0v-274U",
        "outputId": "719f51e8-a872-4140-906a-11775a2b9a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/finrl/plot.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"daily_return\"] = df[value_col_name].pct_change(1)\n",
            "<ipython-input-22-3bdb5b7c979b>:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  portfolio_cumprod =(portfolio.account_value.pct_change()+1).cumprod()-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annual return          0.448711\n",
            "Cumulative returns     0.545573\n",
            "Annual volatility      0.139414\n",
            "Sharpe ratio           2.739104\n",
            "Calmar ratio           4.838323\n",
            "Stability              0.951140\n",
            "Max drawdown          -0.092741\n",
            "Omega ratio            1.593154\n",
            "Sortino ratio          4.473841\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.265439\n",
            "Daily value at risk   -0.016049\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/finrl/plot.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"daily_return\"] = df[value_col_name].pct_change(1)\n",
            "<ipython-input-22-3bdb5b7c979b>:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  portfolio_cumprod =(portfolio.account_value.pct_change()+1).cumprod()-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annual return          0.326904\n",
            "Cumulative returns     0.394080\n",
            "Annual volatility      0.237092\n",
            "Sharpe ratio           1.315255\n",
            "Calmar ratio           2.309310\n",
            "Stability              0.764990\n",
            "Max drawdown          -0.141559\n",
            "Omega ratio            1.261024\n",
            "Sortino ratio          2.083729\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.085499\n",
            "Daily value at risk   -0.028633\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/finrl/plot.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"daily_return\"] = df[value_col_name].pct_change(1)\n",
            "<ipython-input-22-3bdb5b7c979b>:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  portfolio_cumprod =(portfolio.account_value.pct_change()+1).cumprod()-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annual return          0.237458\n",
            "Cumulative returns     0.284359\n",
            "Annual volatility      0.140232\n",
            "Sharpe ratio           1.594979\n",
            "Calmar ratio           4.091536\n",
            "Stability              0.897847\n",
            "Max drawdown          -0.058036\n",
            "Omega ratio            1.304199\n",
            "Sortino ratio          2.422862\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.052346\n",
            "Daily value at risk   -0.016780\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/finrl/plot.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"daily_return\"] = df[value_col_name].pct_change(1)\n",
            "<ipython-input-22-3bdb5b7c979b>:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  portfolio_cumprod =(portfolio.account_value.pct_change()+1).cumprod()-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annual return          0.652133\n",
            "Cumulative returns     0.803501\n",
            "Annual volatility      0.175031\n",
            "Sharpe ratio           2.967815\n",
            "Calmar ratio           8.877087\n",
            "Stability              0.961916\n",
            "Max drawdown          -0.073463\n",
            "Omega ratio            1.680666\n",
            "Sortino ratio          5.130380\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.268842\n",
            "Daily value at risk   -0.019991\n",
            "dtype: float64\n",
            "Annual return            1328.842012\n",
            "Cumulative returns       4668.016991\n",
            "Annual volatility           0.415912\n",
            "Sharpe ratio               17.791631\n",
            "Calmar ratio           458163.416518\n",
            "Stability                   0.982240\n",
            "Max drawdown               -0.002900\n",
            "Omega ratio              1516.148969\n",
            "Sortino ratio            1980.219123\n",
            "Skew                             NaN\n",
            "Kurtosis                         NaN\n",
            "Tail ratio                  9.072624\n",
            "Daily value at risk        -0.023036\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/site-packages/finrl/plot.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"daily_return\"] = df[value_col_name].pct_change(1)\n",
            "<ipython-input-22-3bdb5b7c979b>:59: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  portfolio_cumprod =(portfolio.account_value.pct_change()+1).cumprod()-1\n"
          ]
        }
      ],
      "source": [
        "def output_predict(model, reference_model = False):\n",
        "  meta_coefficient = {\"date\":[], \"weights\":[]}\n",
        "\n",
        "  portfolio = pd.DataFrame(index = range(1), columns = unique_trade_date)\n",
        "  initial_capital = 1000000\n",
        "  portfolio.loc[0,unique_trade_date[0]] = initial_capital\n",
        "\n",
        "  for i in range(len(unique_trade_date) - 1):\n",
        "\n",
        "      current_date = unique_trade_date[i]\n",
        "      next_date = unique_trade_date[i+1]\n",
        "      df_current = df[df.date==current_date].reset_index(drop=True)\n",
        "      tics = df_current['tic'].values\n",
        "      features = df_current[tech_indicator_list].values\n",
        "      df_next = df[df.date==next_date].reset_index(drop=True)\n",
        "      if not reference_model:\n",
        "        predicted_y = model.predict(features)\n",
        "        mu = predicted_y\n",
        "        Sigma = risk_models.sample_cov(df_current.return_list[0], returns_data=True)\n",
        "      else:\n",
        "        mu = df_next.return_list[0].loc[next_date].values\n",
        "        Sigma = risk_models.sample_cov(df_next.return_list[0], returns_data=True)\n",
        "      predicted_y_df = pd.DataFrame({\"tic\":tics.reshape(-1,), \"predicted_y\":mu.reshape(-1,)})\n",
        "      min_weight, max_weight = 0, 1\n",
        "      ef = EfficientFrontier(mu, Sigma)\n",
        "      weights = ef.nonconvex_objective(\n",
        "          objective_functions.sharpe_ratio,\n",
        "          objective_args=(ef.expected_returns, ef.cov_matrix),\n",
        "          weights_sum_to_one=True,\n",
        "          constraints=[\n",
        "              {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},  # greater than min_weight\n",
        "              {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},  # less than max_weight\n",
        "          ],\n",
        "      )\n",
        "\n",
        "      weight_df = {\"tic\":[], \"weight\":[]}\n",
        "      meta_coefficient[\"date\"] += [current_date]\n",
        "      # it = 0\n",
        "      for item in weights:\n",
        "        weight_df['tic'] += [item]\n",
        "        weight_df['weight'] += [weights[item]]\n",
        "\n",
        "      weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on = ['tic'])\n",
        "      meta_coefficient[\"weights\"] += [weight_df]\n",
        "      cap = portfolio.iloc[0, i]\n",
        "      #current cash invested for each stock\n",
        "      current_cash = [element * cap for element in list(weights.values())]\n",
        "      # current held shares\n",
        "      current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
        "      # next time period price\n",
        "      next_price = np.array(df_next.close)\n",
        "      portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
        "\n",
        "  portfolio=portfolio.T\n",
        "  portfolio.columns = ['account_value']\n",
        "  portfolio = portfolio.reset_index()\n",
        "  portfolio.columns = ['date', 'account_value']\n",
        "  stats = backtest_stats(portfolio, value_col_name = 'account_value')\n",
        "  portfolio_cumprod =(portfolio.account_value.pct_change()+1).cumprod()-1\n",
        "\n",
        "  return portfolio, stats, portfolio_cumprod, pd.DataFrame(meta_coefficient)\n",
        "\n",
        "lr_portfolio, lr_stats, lr_cumprod, lr_weights = output_predict(lr_model)\n",
        "dt_portfolio, dt_stats, dt_cumprod, dt_weights = output_predict(dt_model)\n",
        "svm_portfolio, svm_stats, svm_cumprod, svm_weights = output_predict(svm_model)\n",
        "rf_portfolio, rf_stats, rf_cumprod, rf_weights = output_predict(rf_model)\n",
        "reference_portfolio, reference_stats, reference_cumprod, reference_weights = output_predict(None, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_pDu_152D2e"
      },
      "source": [
        "# Part 7: Explanation Method Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzeU46e2kxy"
      },
      "source": [
        "### Integrated Gradient\n",
        ">* Reference: [Integrated Gradients](https://www.tensorflow.org/tutorials/interpretability/integrated_gradients)\n",
        "\n",
        "Implement the explanation method using integrated gradients and regression coefficients.\n",
        "The formula for Integrated Gradients is as follows:\n",
        "\n",
        "$IntegratedGradients_{i}(x) ::= (x_{i} - x'_{i})\\times\\int_{\\alpha=0}^1\\frac{\\partial F(x'+\\alpha \\times (x - x'))}{\\partial x_i}{d\\alpha}$\n",
        "\n",
        "where:\n",
        "\n",
        "$_{i}$ = feature   \n",
        "$x$ = input  \n",
        "$x'$ = baseline   \n",
        "$\\alpha$ = interpolation constant to perturb features by\n",
        "\n",
        "\n",
        "In practice, computing a definite integral is not always numerically possible and can be computationally costly, so you compute the following numerical approximation:\n",
        "\n",
        "$IntegratedGrads^{approx}_{i}(x)::=(x_{i}-x'_{i})\\times\\sum_{k=1}^{m}\\frac{\\partial F(x' + \\frac{k}{m}\\times(x - x'))}{\\partial x_{i}} \\times \\frac{1}{m}$\n",
        "\n",
        "where:\n",
        "\n",
        "$_{i}$ = feature (individual pixel)  \n",
        "$x$ = input (image tensor)  \n",
        "$x'$ = baseline (image tensor)  \n",
        "$k$ = scaled feature perturbation constant  \n",
        "$m$ = number of steps in the Riemann sum approximation of the integral  \n",
        "$(x_{i}-x'_{i})$ = a term for the difference from the baseline. This is necessary to scale the integrated gradients and keep them in terms of the original image. The path from the baseline image to the input is in pixel space. Since with IG you are integrating in a straight line (linear transformation) this ends up being roughly equivalent to the integral term of the derivative of the interpolated image function with respect to $\\alpha$ with enough steps. The integral sums each pixel's gradient times the change in the pixel along the path. It's simpler to implement this integration as uniform steps from one image to the other, substituting $x := (x' + \\alpha(x-x'))$. So the change of variables gives $dx = (x-x')d\\alpha$. The $(x-x')$ term is constant and is factored out of the integral."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7_UAJ9eYPtiu"
      },
      "outputs": [],
      "source": [
        "def calculate_gradient(model, interpolated_input, actions,  feature_idx, stock_idx, h = 1e-1):\n",
        "  forward_input = interpolated_input\n",
        "  forward_input[feature_idx + stock_dimension][stock_idx] += h\n",
        "  forward_Q = model.policy.evaluate_actions(torch.cuda.FloatTensor(forward_input).reshape(-1,stock_dimension*(stock_dimension + feature_dimension)), torch.cuda.FloatTensor(actions).reshape(-1,stock_dimension))\n",
        "  interpolated_Q = model.policy.evaluate_actions(torch.cuda.FloatTensor(interpolated_input).reshape(-1,stock_dimension*(stock_dimension + feature_dimension)), torch.cuda.FloatTensor(actions).reshape(-1,stock_dimension))\n",
        "  forward_Q = forward_Q[0].detach().cpu().numpy()[0]\n",
        "  interpolated_Q = interpolated_Q[0].detach().cpu().numpy()[0]\n",
        "  return (forward_Q - interpolated_Q) / h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cY_q0OoF33dB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "b6bab99e-4ef3-48f4-eb5e-31071a6747ec"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-877293223120>:4: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  forward_Q = model.policy.evaluate_actions(torch.cuda.FloatTensor(forward_input).reshape(-1,stock_dimension*(stock_dimension + feature_dimension)), torch.cuda.FloatTensor(actions).reshape(-1,stock_dimension))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-73be34f43386>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0minterpolated_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbaseline_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# N x K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0minterpolated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolated_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           \u001b[0minterpolated_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprec_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0mavg_interpolated_grad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minterpolated_gradient\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-877293223120>\u001b[0m in \u001b[0;36mcalculate_gradient\u001b[0;34m(model, interpolated_input, actions, feature_idx, stock_idx, h)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mforward_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolated_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mforward_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstock_dimension\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstock_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mforward_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstock_dimension\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_dimension\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeature_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstock_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0minterpolated_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolated_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstock_dimension\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_dimension\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeature_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstock_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mforward_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_Q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import copy\n",
        "meta_Q = {\"date\":[], \"feature\":[], \"Saliency Map\":[], \"algo\":[]}\n",
        "\n",
        "for algo in {\"A2C\", \"PPO\"}:\n",
        "  if algo == \"A2C\":\n",
        "    prec_step = 1e-2\n",
        "  else:\n",
        "    prec_step = 1e-1\n",
        "\n",
        "  model = eval(\"trained_\" + algo.lower())\n",
        "  df_actions = eval(\"df_actions_\" + algo.lower())\n",
        "  for i in range(len(unique_trade_date)-1):\n",
        "    date = unique_trade_date[i]\n",
        "    covs = trade[trade['date'] == date].cov_list.iloc[0]\n",
        "    features = trade[trade['date'] == date][tech_indicator_list].values # N x K\n",
        "    actions = df_actions.loc[date].values\n",
        "\n",
        "    for feature_idx in range(len(tech_indicator_list)):\n",
        "\n",
        "      int_grad_per_feature = 0\n",
        "      for stock_idx in range(features.shape[0]):#N\n",
        "\n",
        "        int_grad_per_stock = 0\n",
        "        avg_interpolated_grad = 0\n",
        "        for alpha in range(1, 51):\n",
        "          scale = 1/50\n",
        "          baseline_features = copy.deepcopy(features)\n",
        "          baseline_noise = np.random.normal(0, 1, stock_dimension)\n",
        "          baseline_features[:,feature_idx] = [0] * stock_dimension\n",
        "          interpolated_features = baseline_features + scale * alpha * (features - baseline_features) # N x K\n",
        "          interpolated_input = np.append(covs, interpolated_features.T, axis = 0)\n",
        "          interpolated_gradient = calculate_gradient(model, interpolated_input, actions, feature_idx, stock_idx, h = prec_step)[0]\n",
        "\n",
        "          avg_interpolated_grad += interpolated_gradient * scale\n",
        "        int_grad_per_stock = (features[stock_idx][feature_idx] - 0) * avg_interpolated_grad\n",
        "        int_grad_per_feature += int_grad_per_stock\n",
        "\n",
        "      meta_Q['date'] += [date]\n",
        "      meta_Q['algo'] += [algo]\n",
        "      meta_Q['feature'] += [tech_indicator_list[feature_idx]]\n",
        "      meta_Q['Saliency Map'] += [int_grad_per_feature]\n",
        "\n",
        "meta_Q = pd.DataFrame(meta_Q)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI0UkiCb2pLD"
      },
      "source": [
        "### Regression Coefficient\n",
        "Implement the linear regression to measure the feature weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNHzRWPvQIsu"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "meta_score_coef = {\"date\":[], \"coef\":[], \"algo\":[]}\n",
        "\n",
        "for algo in [\"LR\", \"RF\", \"Reference Model\", \"SVM\", \"DT\", \"A2C\", \"PPO\"]:\n",
        "  if algo == \"LR\":\n",
        "    weights = lr_weights\n",
        "  elif algo == \"RF\":\n",
        "    weights = rf_weights\n",
        "  elif algo == \"DT\":\n",
        "    weights = dt_weights\n",
        "  elif algo == \"SVM\":\n",
        "    weights = svm_weights\n",
        "  elif algo == \"A2C\":\n",
        "    weights = a2c_weights\n",
        "  elif algo == \"PPO\":\n",
        "    weights = ppo_weights\n",
        "  else:\n",
        "    weights = reference_weights\n",
        "\n",
        "  for i in range(len(unique_trade_date) - 1):\n",
        "    date = unique_trade_date[i]\n",
        "    next_date = unique_trade_date[i+1]\n",
        "    df_temp = df[df.date==date].reset_index(drop=True)\n",
        "    df_temp_next = df[df.date==next_date].reset_index(drop=True)\n",
        "    weight_piece = weights[weights.date == date].iloc[0]['weights']\n",
        "    piece_return = pd.DataFrame(df_temp_next.return_list.iloc[0].loc[next_date]).reset_index()\n",
        "    piece_return.columns = ['tic', 'return']\n",
        "    X = df_temp[['macd','rsi_30', 'cci_30', 'dx_30', 'tic']]\n",
        "    X_next = df_temp_next[['macd','rsi_30', 'cci_30', 'dx_30', 'tic']]\n",
        "    piece = weight_piece.merge(X, on = 'tic').merge(piece_return, on = 'tic')\n",
        "    piece['Y'] = piece['return'] * piece['weight']\n",
        "    X = piece[['macd','rsi_30', 'cci_30', 'dx_30']]\n",
        "    X = sm.add_constant(X)\n",
        "    Y = piece[['Y']]\n",
        "    model = sm.OLS(Y,X)\n",
        "    results = model.fit()\n",
        "    meta_score_coef[\"coef\"] += [(X * results.params).sum(axis = 0)]\n",
        "    meta_score_coef[\"date\"] += [date]\n",
        "    meta_score_coef[\"algo\"] += [algo]\n",
        "\n",
        "meta_score_coef = pd.DataFrame(meta_score_coef)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaCnRr2K4DuP"
      },
      "source": [
        "### Correlation Coefficient\n",
        "Calculate the  sing-step and multi-step correlation coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKWHxdK-QQxU"
      },
      "outputs": [],
      "source": [
        "performance_score = {\"date\":[], \"algo\":[], \"score\":[]}\n",
        "\n",
        "for i in range(0, len(unique_trade_date)):\n",
        "  date_ = unique_trade_date[i]\n",
        "  if len(meta_score_coef[(meta_score_coef['date'] == date_)]) == 0:\n",
        "    continue\n",
        "  lr_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'LR')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  rf_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'RF')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  reference_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'Reference Model')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  dt_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'DT')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  svm_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'SVM')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "\n",
        "  saliency_coef_a2c = meta_Q[(meta_Q['date'] == date_) & (meta_Q['algo'] == \"A2C\")]['Saliency Map'].values\n",
        "  saliency_coef_ppo = meta_Q[(meta_Q['date'] == date_) & (meta_Q['algo'] == \"PPO\")]['Saliency Map'].values\n",
        "\n",
        "  lr_score = np.corrcoef(lr_coef, reference_coef)[0][1]\n",
        "  rf_score = np.corrcoef(rf_coef, reference_coef)[0][1]\n",
        "  dt_score = np.corrcoef(dt_coef, reference_coef)[0][1]\n",
        "  svm_score = np.corrcoef(svm_coef, reference_coef)[0][1]\n",
        "  saliency_score_a2c = np.corrcoef(saliency_coef_a2c, reference_coef)[0][1]\n",
        "  saliency_score_ppo = np.corrcoef(saliency_coef_ppo, reference_coef)[0][1]\n",
        "\n",
        "  for algo in [\"LR\",\"A2C\",\"PPO\",\"RF\",\"DT\", \"SVM\"]:\n",
        "    performance_score[\"date\"] += [date_]\n",
        "    performance_score[\"algo\"] += [algo]\n",
        "    if algo == \"LR\":\n",
        "      score = lr_score\n",
        "    elif algo == \"RF\":\n",
        "      score = rf_score\n",
        "    elif algo == \"DT\":\n",
        "      score = dt_score\n",
        "    elif algo == \"A2C\":\n",
        "      score = saliency_score_a2c\n",
        "    elif algo == \"SVM\":\n",
        "      score = svm_score\n",
        "    else:\n",
        "      score = saliency_score_ppo\n",
        "    performance_score[\"score\"] += [score]\n",
        "\n",
        "performance_score = pd.DataFrame(performance_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em0Dx9p_kwrR"
      },
      "outputs": [],
      "source": [
        "multi_performance_score = {\"date\":[], \"algo\":[], \"score\":[]}\n",
        "window = 20\n",
        "for i in range(len(unique_trade_date) - window ):\n",
        "  date_ = unique_trade_date[i]\n",
        "  if len(meta_score_coef[(meta_score_coef['date'] == date_)]) == 0:\n",
        "    continue\n",
        "  lr_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'LR')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  rf_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'RF')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  reference_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'Reference Model')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  for w in range(1, window):\n",
        "      date_f = unique_trade_date[i + w]\n",
        "      prx_coef = meta_score_coef[(meta_score_coef['date'] == date_f) & (meta_score_coef['algo'] == 'Reference Model')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "      reference_coef += prx_coef\n",
        "  reference_coef = reference_coef / window\n",
        "  dt_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'DT')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  svm_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'SVM')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  saliency_coef_a2c = meta_Q[(meta_Q['date'] == date_) & (meta_Q['algo'] == \"A2C\")]['Saliency Map'].values\n",
        "  saliency_coef_ppo = meta_Q[(meta_Q['date'] == date_) & (meta_Q['algo'] == \"PPO\")]['Saliency Map'].values\n",
        "  lr_score = np.corrcoef(lr_coef, reference_coef)[0][1]\n",
        "  rf_score = np.corrcoef(rf_coef, reference_coef)[0][1]\n",
        "  dt_score = np.corrcoef(dt_coef, reference_coef)[0][1]\n",
        "  svm_score = np.corrcoef(svm_coef, reference_coef)[0][1]\n",
        "  saliency_score_a2c = np.corrcoef(saliency_coef_a2c, reference_coef)[0][1]\n",
        "  saliency_score_ppo = np.corrcoef(saliency_coef_ppo, reference_coef)[0][1]\n",
        "\n",
        "  for algo in [\"LR\", \"A2C\", \"RF\", \"PPO\", \"DT\", \"SVM\"]:\n",
        "    multi_performance_score[\"date\"] += [date_]\n",
        "    multi_performance_score[\"algo\"] += [algo]\n",
        "    if algo == \"LR\":\n",
        "      score = lr_score\n",
        "    elif algo == \"RF\":\n",
        "      score = rf_score\n",
        "    elif algo == \"DT\":\n",
        "      score = dt_score\n",
        "    elif algo == \"A2C\":\n",
        "      score = saliency_score_a2c\n",
        "    elif algo == \"SVM\":\n",
        "      score = svm_score\n",
        "    else:\n",
        "      score = saliency_score_ppo\n",
        "    multi_performance_score[\"score\"] += [score]\n",
        "\n",
        "multi_performance_score = pd.DataFrame(multi_performance_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yeGe06I3gGj"
      },
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDCuI-85fBgB"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "trace1_portfolio = go.Scatter(x = time_ind, y = a2c_cumpod, mode = 'lines', name = 'A2C')\n",
        "trace2_portfolio = go.Scatter(x = time_ind, y = ppo_cumpod, mode = 'lines', name = 'PPO')\n",
        "trace3_portfolio = go.Scatter(x = time_ind, y = dji_cumpod, mode = 'lines', name = 'DJIA')\n",
        "trace4_portfolio = go.Scatter(x = time_ind, y = lr_cumprod, mode = 'lines', name = 'LR')\n",
        "trace5_portfolio = go.Scatter(x = time_ind, y = rf_cumprod, mode = 'lines', name = 'RF')\n",
        "trace6_portfolio = go.Scatter(x = time_ind, y = dt_cumprod, mode = 'lines', name = 'DT')\n",
        "trace7_portfolio = go.Scatter(x = time_ind, y = svm_cumprod, mode = 'lines', name = 'SVM')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XClvP1WifJB_"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(trace1_portfolio)\n",
        "fig.add_trace(trace2_portfolio)\n",
        "\n",
        "fig.add_trace(trace3_portfolio)\n",
        "\n",
        "fig.add_trace(trace4_portfolio)\n",
        "fig.add_trace(trace5_portfolio)\n",
        "fig.add_trace(trace6_portfolio)\n",
        "fig.add_trace(trace7_portfolio)\n",
        "\n",
        "fig.update_layout(\n",
        "    legend=dict(\n",
        "        x=0,\n",
        "        y=1,\n",
        "        traceorder=\"normal\",\n",
        "        font=dict(\n",
        "            family=\"sans-serif\",\n",
        "            size=15,\n",
        "            color=\"black\"\n",
        "        ),\n",
        "        bgcolor=\"White\",\n",
        "        bordercolor=\"white\",\n",
        "        borderwidth=2\n",
        "\n",
        "    ),\n",
        ")\n",
        "fig.update_layout(title={\n",
        "        #'text': \"Cumulative Return using FinRL\",\n",
        "        'y':0.85,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'})\n",
        "\n",
        "fig.update_layout(\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis = dict(titlefont = dict(size = 30), title = \"Cumulative Return\"),\n",
        "    font=dict(\n",
        "        size=40,\n",
        "    ),\n",
        ")\n",
        "fig.update_layout(font_size = 20)\n",
        "fig.update_traces(line=dict(width=2))\n",
        "\n",
        "fig.update_xaxes(showline=True, linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "\n",
        "fig.show(\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0WhtMDgHz1p"
      },
      "source": [
        "#### We found that A2C and PPO succeeded in the portfoli management task and is better than all other algorithms/benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxlehwfPfUMx"
      },
      "outputs": [],
      "source": [
        "meta_score = {\"Annual return\":[], \"Annual volatility\":[], \"Max drawdown\":[], \"Sharpe ratio\":[], \"Algorithm\":[], \"Calmar ratio\":[]}\n",
        "for name in [\"LR\", \"A2C\", \"RF\", \"Reference Model\", \"PPO\", \"SVM\", \"DT\", \"DJI\"]:\n",
        "  if name == \"DT\":\n",
        "    annualreturn = dt_stats[\"Annual return\"]\n",
        "    annualvol = dt_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = dt_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = dt_stats[\"Max drawdown\"]\n",
        "    calmarratio = dt_stats[\"Calmar ratio\"]\n",
        "  elif name == \"LR\":\n",
        "    annualreturn = lr_stats[\"Annual return\"]\n",
        "    annualvol = lr_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = lr_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = lr_stats[\"Max drawdown\"]\n",
        "    calmarratio = lr_stats[\"Calmar ratio\"]\n",
        "  elif name == \"SVM\":\n",
        "    annualreturn = svm_stats[\"Annual return\"]\n",
        "    annualvol = svm_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = svm_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = svm_stats[\"Max drawdown\"]\n",
        "    calmarratio = svm_stats[\"Calmar ratio\"]\n",
        "  elif name == \"RF\":\n",
        "    annualreturn = rf_stats[\"Annual return\"]\n",
        "    annualvol = rf_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = rf_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = rf_stats[\"Max drawdown\"]\n",
        "    calmarratio = rf_stats[\"Calmar ratio\"]\n",
        "  elif name == \"Reference Model\":\n",
        "    annualreturn = reference_stats[\"Annual return\"]\n",
        "    annualvol = reference_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = reference_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = reference_stats[\"Max drawdown\"]\n",
        "    calmarratio = reference_stats[\"Calmar ratio\"]\n",
        "  elif name == \"PPO\":\n",
        "    annualreturn = perf_stats_all_ppo[\"Annual return\"]\n",
        "    annualvol = perf_stats_all_ppo[\"Annual volatility\"]\n",
        "    sharpeRatio = perf_stats_all_ppo[\"Sharpe ratio\"]\n",
        "    maxdradown = perf_stats_all_ppo[\"Max drawdown\"]\n",
        "    calmarratio = perf_stats_all_ppo[\"Calmar ratio\"]\n",
        "  elif name == \"DJI\":\n",
        "    annualreturn = baseline_df_stats[\"Annual return\"]\n",
        "    annualvol = baseline_df_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = baseline_df_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = baseline_df_stats[\"Max drawdown\"]\n",
        "    calmarratio = baseline_df_stats[\"Calmar ratio\"]\n",
        "  else:\n",
        "    annualreturn = perf_stats_all_a2c[\"Annual return\"]\n",
        "    annualvol = perf_stats_all_a2c[\"Annual volatility\"]\n",
        "    sharpeRatio = perf_stats_all_a2c[\"Sharpe ratio\"]\n",
        "    maxdradown = perf_stats_all_a2c[\"Max drawdown\"]\n",
        "    calmarratio = perf_stats_all_a2c[\"Calmar ratio\"]\n",
        "  meta_score[\"Algorithm\"] += [name]\n",
        "  meta_score[\"Annual return\"] += [annualreturn]\n",
        "  meta_score[\"Annual volatility\"] += [annualvol]\n",
        "  meta_score[\"Max drawdown\"] += [maxdradown]\n",
        "  meta_score[\"Sharpe ratio\"] += [sharpeRatio]\n",
        "  meta_score[\"Calmar ratio\"] += [calmarratio]\n",
        "\n",
        "meta_score = pd.DataFrame(meta_score).sort_values(\"Sharpe ratio\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7sK4kM8QyEu"
      },
      "outputs": [],
      "source": [
        "postiveRatio = pd.DataFrame(performance_score.groupby(\"algo\").apply(lambda x : np.mean(x['score'])))\n",
        "\n",
        "postiveRatio = postiveRatio.reset_index()\n",
        "postiveRatio.columns = ['algo', 'avg_correlation_coefficient']\n",
        "postiveRatio['Sharpe Ratio'] = [0] * 6\n",
        "\n",
        "# postiveRatio.plot.bar(x = 'algo', y = 'avg_correlation_coefficient')\n",
        "\n",
        "postiveRatiom = pd.DataFrame(multi_performance_score.groupby(\"algo\").apply(lambda x : np.mean(x['score'])))\n",
        "postiveRatiom = postiveRatiom.reset_index()\n",
        "postiveRatiom.columns = ['algo', 'avg_correlation_coefficient']\n",
        "postiveRatiom['Sharpe Ratio'] = [0] * 6\n",
        "\n",
        "# postiveRatiom.plot.bar(x = 'algo', y = 'avg_correlation_coefficient')\n",
        "\n",
        "\n",
        "for algo in ['A2C', 'PPO', 'LR','DT', 'RF', 'SVM']:\n",
        "  postiveRatio.loc[postiveRatio['algo'] == algo, 'Sharpe Ratio'] = meta_score.loc[meta_score['Algorithm'] == algo,'Sharpe ratio'].values[0]\n",
        "  postiveRatiom.loc[postiveRatio['algo'] == algo, 'Sharpe Ratio'] = meta_score.loc[meta_score['Algorithm'] == algo,'Sharpe ratio'].values[0]\n",
        "\n",
        "postiveRatio.sort_values(\"Sharpe Ratio\", inplace= True)\n",
        "\n",
        "postiveRatiom.sort_values(\"Sharpe Ratio\", inplace= True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rLjcOmRBjeu"
      },
      "outputs": [],
      "source": [
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Create figure with secondary y-axis\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# Add traces\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=postiveRatiom['algo'], y=postiveRatiom['Sharpe Ratio'], name=\"Sharpe Ratio\", marker_size = 15, line_width=5),\n",
        "    secondary_y=True,\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Bar(x=postiveRatiom['algo'], y=postiveRatiom['avg_correlation_coefficient'], name=\"Multi-Step Average Correlation Coefficient          \", width\n",
        "    =0.38),\n",
        "    secondary_y=False,\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Bar(x=postiveRatio['algo'], y=postiveRatio['avg_correlation_coefficient'], name=\"Single-Step Average Correlation Coefficient           \", width\n",
        "    =0.38),\n",
        "    secondary_y=False,\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        ")\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=1.5,\n",
        "    xanchor=\"right\",\n",
        "    x=0.95\n",
        "))\n",
        "fig.update_layout(font_size = 15)\n",
        "\n",
        "# Set x-axis title\n",
        "fig.update_xaxes(title_text=\"Model\")\n",
        "fig.update_xaxes(showline=True, linecolor='black',showgrid=True,gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, secondary_y=False, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "# Set y-axes titles\n",
        "fig.update_yaxes(title_text=\"Average Correlation Coefficient\", secondary_y=False, range = [-0.1,0.1])\n",
        "fig.update_yaxes(title_text=\"Sharpe Ratio\", secondary_y=True,range = [-0.5,2.5])\n",
        "\n",
        "fig.show(\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5vQar1zIACp"
      },
      "source": [
        "#### The correlation coefficient represents the level of prediction power.\n",
        "\n",
        "We found that:\n",
        ">*  The sharpe ratio is in accordance with both single-step and  multi-step average correlation coefficient.\n",
        ">* DRL agents is better at multi-step prediction than ML algorithms while worse at single-step prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaMzEa2UxmI6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "fig = make_subplots(rows=2, cols=3)\n",
        "\n",
        "trace0 = go.Histogram(x=performance_score[performance_score['algo'] == 'A2C']['score'].values, nbinsx=25, name = 'A2C',histnorm='probability')\n",
        "trace1 = go.Histogram(x=performance_score[performance_score['algo'] == 'PPO']['score'].values, nbinsx=25, name = 'PPO',histnorm='probability')\n",
        "trace2 = go.Histogram(x=performance_score[performance_score['algo'] == 'DT']['score'].values, nbinsx=25, name = 'DT',histnorm='probability')\n",
        "trace3 = go.Histogram(x=performance_score[performance_score['algo'] == 'LR']['score'].values, nbinsx=25, name = 'LR',histnorm='probability')\n",
        "trace4 = go.Histogram(x=performance_score[performance_score['algo'] == 'SVM']['score'].values, nbinsx=25, name = 'SVM',histnorm='probability')\n",
        "trace5 = go.Histogram(x=performance_score[performance_score['algo'] == 'RF']['score'].values, nbinsx=25, name = 'RF',histnorm='probability')\n",
        "\n",
        "\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig.append_trace(trace2, 1, 3)\n",
        "fig.append_trace(trace3, 2, 1)\n",
        "fig.append_trace(trace4, 2, 2)\n",
        "fig.append_trace(trace5, 2, 3)\n",
        "# Update xaxis properties\n",
        "fig.update_xaxes(title_text=\"Correlation coefficient\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
        "\n",
        "fig.update_layout(\n",
        "\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        "     font=dict(\n",
        "\n",
        "        size=18,\n",
        "    ),\n",
        "\n",
        ")\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=0.99,\n",
        "    xanchor=\"left\",\n",
        "    x=1\n",
        "))\n",
        "\n",
        "fig.update_xaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "\n",
        "fig.show(\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwiYdXs2IgZl"
      },
      "source": [
        "#### Histogram of single-step correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyj3_rmFF42y"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "fig = make_subplots(rows=2, cols=3)\n",
        "\n",
        "trace0 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'A2C']['score'].values, nbinsx=25, name = 'A2C',histnorm='probability')\n",
        "trace1 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'PPO']['score'].values, nbinsx=25, name = 'PPO',histnorm='probability')\n",
        "trace2 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'DT']['score'].values, nbinsx=25, name = 'DT',histnorm='probability')\n",
        "trace3 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'LR']['score'].values, nbinsx=25, name = 'LR',histnorm='probability')\n",
        "trace4 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'SVM']['score'].values, nbinsx=25, name = 'SVM',histnorm='probability')\n",
        "trace5 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'RF']['score'].values, nbinsx=25, name = 'RF',histnorm='probability')\n",
        "\n",
        "fig.update_layout(yaxis1 = dict(range=[0, 0.2]))\n",
        "fig.update_layout(yaxis2 = dict(range=[0, 0.2]))\n",
        "fig.update_layout(yaxis3 = dict(range=[0, 0.4]))\n",
        "fig.update_layout(yaxis4 = dict(range=[0, 0.4]))\n",
        "fig.update_layout(yaxis5 = dict(range=[0, 0.4]))\n",
        "fig.update_layout(yaxis6 = dict(range=[0, 0.4]))\n",
        "\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig.append_trace(trace2, 1, 3)\n",
        "fig.append_trace(trace3, 2, 1)\n",
        "fig.append_trace(trace4, 2, 2)\n",
        "fig.append_trace(trace5, 2, 3)\n",
        "# Update xaxis properties\n",
        "fig.update_xaxes(title_text=\"Correlation coefficient\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
        "\n",
        "fig.update_layout(\n",
        "\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        "     font=dict(\n",
        "\n",
        "        size=18,\n",
        "    ),\n",
        "\n",
        ")\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=0.99,\n",
        "    xanchor=\"left\",\n",
        "    x=1\n",
        "))\n",
        "\n",
        "fig.update_xaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "\n",
        "fig.show(\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JQCKXP-ImaL"
      },
      "source": [
        "#### Histogram of multi-step correlation coefficient"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FinRL: explainable deep reinforcement learning for portfolio management: an empirical approach.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}